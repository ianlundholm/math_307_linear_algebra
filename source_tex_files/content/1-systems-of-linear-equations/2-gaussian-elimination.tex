\section{Gaussian Elimination}
\label{sec:1_2}

\index{gaussian elimination!systems of linear equations and}\index{system of linear equations!gaussian elimination}
The algebraic method\index{algebraic method}\index{solution!algebraic method} introduced in the preceding section can be summarized as follows: Given a system of linear equations, use a sequence of elementary row operations to carry the augmented matrix to a ``nice'' matrix (meaning that the corresponding equations are easy to solve). In Example \ref{exa:000809}, this nice matrix took the form
\begin{equation*}
\leftB \begin{array}{rrr|r}
	1 & 0 & 0 & * \\
	0 & 1 & 0 & * \\
	0 & 0 & 1 & *
\end{array} \rightB
\end{equation*}
The following definitions identify the nice matrices that arise in this process.


\begin{definition}{Row-Echelon Form (Reduced)}{000992}
A matrix is said to be in \index{row-echelon form}\textbf{row-echelon form} (and will be called a \index{row-echelon matrix}\index{matrix form!row-echelon form}\index{matrix!row-echelon matrix}\textbf{row-echelon matrix}) if it satisfies the following three conditions:

\begin{enumerate}
\item All \index{zero rows}\index{rows!zero rows}\textbf{zero rows} (consisting entirely of zeros) are at the bottom.

\item The first nonzero entry from the left in each nonzero row is a $1$, called the \textbf{leading 1}\index{leading $1$}\index{rows!leading $1$} for that row.

\item Each leading $1$ is to the right of all leading $1$s in the rows above it.

\end{enumerate}

A row-echelon matrix is said to be in \index{reduced row-echelon form}\textbf{reduced row-echelon form} (and will be called a \index{reduced row-echelon matrix}\index{matrix!reduced row-echelon matrix}\index{matrix form!reduced row-echelon form}\textbf{reduced row-echelon matrix}) if, in addition, it satisfies the following condition:

\begin{enumerate}
\setcounter{enumi}{3}
\item Each leading $1$ is the only nonzero entry in its column.

\end{enumerate}
\end{definition}

\noindent The row-echelon matrices have a ``staircase'' form\index{staircase form}, as indicated by the following example (the asterisks indicate arbitrary numbers).
\begin{equation*}
\leftB \begin{array}{rrrrrrr}
	\multicolumn{1}{r|}{0} & 1 & * & * & * & * & * \\ 
	\cline{2-3}
	0 & 0 & \multicolumn{1}{r|}{0} & 1 & * & * & * \\
	\cline{4-4}
	0 & 0 & 0 & \multicolumn{1}{r|}{0} & 1 & * & * \\
	\cline{5-6}
	0 & 0 & 0 & 0 & 0 & \multicolumn{1}{r|}{0} & 1 \\
	\cline{7-7}
	0 & 0 & 0 & 0 & 0 & 0 & 0 
\end{array} \rightB
\end{equation*}
The leading $1$s proceed ``down and to the right'' through the matrix. Entries above and to the right of the leading $1$s are arbitrary, but all entries below and to the left of them are zero. Hence, a matrix in row-echelon form is in reduced form if, in addition, the entries directly above each leading $1$ are all zero. Note that a matrix in row-echelon form can, with a few more row operations, be carried to reduced form (use row operations to create zeros above each leading one in succession, beginning from the right).

\begin{example}{}{001009}
The following matrices are in row-echelon form (for any choice of numbers in $*$-positions).
\begin{equation*}
\leftB \begin{array}{rrr}
	1 & * & * \\
	0 & 0 & 1
\end{array} \rightB
\leftB \begin{array}{rrrr}
	0 & 1 & * & * \\
	0 & 0 & 1 & * \\
	0 & 0 & 0 & 0
\end{array} \rightB
\leftB \begin{array}{rrrr}
	1 & * & * & * \\
	0 & 1 & * & * \\
	0 & 0 & 0 & 1 
\end{array} \rightB
\leftB \begin{array}{rrr}
	1 & * & * \\
	0 & 1 & * \\
	0 & 0 & 1
\end{array} \rightB
\end{equation*}
The following, on the other hand, are in reduced row-echelon form.
\begin{equation*}
\leftB \begin{array}{rrr}
	1 & * & 0 \\
	0 & 0 & 1
\end{array} \rightB
\leftB \begin{array}{rrrr}
	0 & 1 & 0 & * \\
	0 & 0 & 1 & * \\
	0 & 0 & 0 & 0
\end{array} \rightB
\leftB \begin{array}{rrrr}
	1 & 0 & * & 0 \\
	0 & 1 & * & 0 \\
	0 & 0 & 0 & 1
\end{array} \rightB
\leftB \begin{array}{rrr}
	1 & 0 & 0 \\
	0 & 1 & 0 \\
	0 & 0 & 1
\end{array} \rightB
\end{equation*}
The choice of the positions for the leading $1$s determines the (reduced) row-echelon form (apart from the numbers in $*$-positions).
\end{example}

The importance of row-echelon matrices comes from the following theorem.\index{matrix!row-echelon matrix}\index{row-echelon matrix}

\begin{theorem}{}{001017}
Every matrix can be brought to (reduced) row-echelon form by a sequence of elementary row operations. \index{matrix form!reduced row-echelon form}\index{matrix form!row-echelon form}\index{reduced row-echelon form}\index{reduced row-echelon matrix}\index{row-echelon form}\index{row-echelon matrix}
\end{theorem}

In fact we can give a step-by-step procedure for actually finding a row-echelon matrix. Observe that while there are many sequences of row operations that will bring a matrix to row-echelon form, the one we use is systematic and is easy to program on a computer. Note that the algorithm deals with matrices in general, possibly with columns of zeros. 

\begin{theorem*}[label=thm:001021]{Gaussian\footnotemark Algorithm\footnotemark}
%\begin{figure}[H]
%\centering
%\includegraphics{1-systems-of-linear-equations/figures/2-gaussian-elimination/ufg01001}
%\caption{\label{fig:001023}}
%\end{figure}

\begin{itemize}
\item[] Step 1. If the matrix consists entirely of zeros, stop---it is already in row-echelon form.

\item[] Step 2. Otherwise, find the first column from the left containing a nonzero entry (call it $a$), and move the row containing that entry to the top position.
\item[] Step 3. Now multiply the new top row by $1/a$ to create a leading $1$.

\item[] Step 4. By subtracting multiples of that row from rows below it, make each entry below the leading $1$ zero.
\end{itemize}

This completes the first row, and all further row operations are carried out on the remaining rows.

\begin{itemize}
\item[] Step 5. Repeat steps 1--4 on the matrix consisting of the remaining rows.
\end{itemize}
The process stops when either no rows remain at step 5 or the remaining rows consist entirely of zeros. \index{gaussian algorithm}
\end{theorem*}
\addtocounter{footnote}{-1}
\footnotetext{Carl Friedrich Gauss (1777--1855)\index{Gauss, Carl Friedrich} ranks with Archimedes\index{Archimedes} and Newton\index{Newton, Sir Isaac} as one of the three greatest mathematicians of all time. He was a child prodigy and, at the age of 21, he gave the first proof that every polynomial has a complex root. In 1801 he published a timeless masterpiece, \textit{Disquisitiones Arithmeticae}\index{\textit{Disquisitiones Arithmeticae} (Gauss)}, in which he founded modern number theory. He went on to make ground-breaking contributions to nearly every branch of mathematics, often well before others rediscovered and published the results.}
\stepcounter{footnote}\footnotetext{The algorithm was known to the ancient Chinese.}

Observe that the gaussian algorithm is recursive\index{recursive algorithm}: When the first leading $1$ has been obtained, the procedure is repeated on the remaining rows of the matrix. This makes the algorithm easy to use on a computer. Note that the solution to Example \ref{exa:000809} did not use the gaussian algorithm as written because the first leading $1$ was not created by dividing row 1 by $3$. The reason for this is that it avoids fractions. However, the general pattern is clear: Create the leading $1$s from left to right, using each of them in turn to create zeros below it. Here are two more examples.

\begin{example}{}{001040}
Solve the following system of equations.
\begin{equation*}
\arraycolsep=1pt
\begin{array}{rlrlrcr}
	3x & + & y & - & 4z & = & -1 \\
	 x &  &   & + & 10z & = & 5 \\
	4x & + & y & + & 6z & = & 1
\end{array}
\end{equation*}
\begin{solution}
The corresponding augmented matrix is
\begin{equation*}
\leftB \begin{array}{rrr|r}
	3 & 1 & -4 & -1 \\
	1 & 0 & 10 & 5 \\
	4 & 1 &  6  & 1
\end{array} \rightB
\end{equation*}
Create the first leading one by interchanging rows 1 and 2
\begin{equation*}
\leftB \begin{array}{rrr|r}
	1 & 0 & 10 & 5 \\
	3 & 1 & -4 & -1 \\
	4 & 1 & 6 & 1
\end{array} \rightB
\end{equation*}
Now subtract $3$ times row 1 from row 2, and subtract $4$ times row 1 from row 3. The result is
\begin{equation*}
\leftB \begin{array}{rrr|r}
	1 & 0 & 10 & 5 \\
	0 & 1 & -34 & -16 \\
	0 & 1 & -34 & -19
\end{array} \rightB
\end{equation*}
Now subtract row 2 from row 3 to obtain
\begin{equation*}
\leftB \begin{array}{rrr|r}
	1 & 0 & 10 & 5 \\
	0 & 1 & -34 & -16 \\
	0 & 0 & 0 & -3
\end{array} \rightB
\end{equation*}
This means that the following reduced system of equations
\begin{equation*}
\arraycolsep=1pt
\begin{array}{rlrlrcr}
	x &  &   & + & 10z & = & 5 \\
	  &  & y & - & 34z & = &-16 \\
	  &  &   &   &   0 & = & -3
\end{array}
\end{equation*}
is equivalent to the original system. In other words, the two have the same solutions. But this last system clearly has no solution (the last equation requires that $x$, $y$ and $z$ satisfy $0x + 0y + 0z = -3$, and no such numbers exist). Hence the original system has no solution.
\end{solution}
\end{example}

\begin{example}{}{001056}
Solve the following system of equations.
\begin{equation*}
\arraycolsep=1pt
\begin{array}{rlrlrlrcr}
	 x_1 & - & 2x_2 & - & x_3 & + & 3x_4 & = & 1 \\
	2x_1 & - & 4x_2 & + & x_3 &   &      & = & 5 \\
	 x_1 & - & 2x_2 & + & 2x_3& - & 3x_4 & = & 4
\end{array}
\end{equation*}
\begin{solution}
The augmented matrix is
\begin{equation*}
\leftB \begin{array}{rrrr|r}
	1 & -2 & -1 &  3 & 1 \\
	2 & -4 &  1 &  0 & 5 \\
	1 & -2 &  2 & -3 & 4
\end{array} \rightB
\end{equation*}
Subtracting twice row 1 from row 2 and subtracting row 1 from row 3 gives
\begin{equation*}
\leftB \begin{array}{rrrr|r}
	1 & -2 & -1 &  3 & 1 \\
	0 & 0  & 3  & -6 & 3 \\
	0 & 0  & 3  & -6 & 3
\end{array} \rightB
\end{equation*}
Now subtract row 2 from row 3 and multiply row 2 by $\frac{1}{3}$ to get
\begin{equation*}
\leftB \begin{array}{rrrr|r}
	1 & -2 & -1 &  3 & 1 \\
	0 &  0 &  1 & -2 & 1 \\
	0 & 0  & 0 & 0 & 0
\end{array} \rightB
\end{equation*}
This is in row-echelon form, and we take it to reduced form by adding row 2 to row 1:
\begin{equation*}
\leftB \begin{array}{rrrr|r}
	1 & -2 & 0 & 1 & 2 \\
	0 &  0 & 1 & -2 & 1 \\
	0 &  0  & 0 & 0 & 0
\end{array} \rightB
\end{equation*}
The corresponding reduced system of equations is
\begin{equation*}
\arraycolsep=1pt
\begin{array}{rlrlrlrcr}
	 x_1 & - & 2x_2 &   &     & + &  x_4 & = & 2 \\
	     &   &      &   & x_3 & - & 2x_4 & = & 1 \\
	     &   &      &   &     &   &    0 & = & 0
\end{array}
\end{equation*}
The leading ones are in columns 1 and 3 here, so the corresponding variables $x_1$ and $x_3$ are called leading variables. Because the matrix is in reduced row-echelon form, these equations can be used to solve for the leading variables in terms of the nonleading variables $x_2$ and $x_4$. More precisely, in the present example we set $x_2 = s$ and $x_4 = t$ where $s$ and $t$ are arbitrary, so these equations become
\begin{equation*}
x_1 - 2s + t = 2 \quad \mbox{and} \quad x_3 - 2t = 1
\end{equation*}
Finally the solutions are given by
\begin{align*}
x_1 &= 2 + 2s - t \\
x_2 &= s \\
x_3 &= 1 + 2t \\
x_4 &= t
\end{align*}
where $s$ and $t$ are arbitrary.
\end{solution}
\end{example}

The solution of Example \ref{exa:001056} is typical of the general case. To solve a linear system, the augmented matrix\index{augmented matrix}\index{matrix!augmented matrix} is carried to reduced row-echelon form, and the variables corresponding to the leading ones are called \index{leading variables}\textbf{leading variables}. Because the matrix is in reduced form, each leading variable occurs in exactly one equation, so that equation can be solved to give a formula for the leading variable in terms of the nonleading variables. It is 
customary to call the nonleading variables ``free'' variables\index{free variables}, and to label them by new variables $s, t, \dots$, called \index{parameters}\textbf{parameters}. Hence, as in Example \ref{exa:001056}, every variable $x_i$ is given by a formula in terms of the parameters $s$ and $t$. Moreover, every choice of these parameters leads to a solution to the system, and every solution arises in this way. This procedure works in general, and has come to be called

\begin{theorem*}[label=thm:001084]{Gaussian Elimination}
To solve a system of linear equations proceed as follows:\index{gaussian elimination!defined}\index{solution!solution to a system}\index{system of linear equations!gaussian elimination}

\begin{enumerate}
\item Carry the augmented matrix\index{augmented matrix}\index{matrix!augmented matrix} to a reduced row-echelon matrix using elementary row operations.

\item If a row $\leftB \begin{array}{cccccc}
0 & 0 & 0 & \cdots & 0 & 1
\end{array} \rightB$ occurs, the system is inconsistent.

\item Otherwise, assign the nonleading variables (if any) as parameters, and use the equations corresponding to the reduced row-echelon matrix to solve for the leading variables in terms of the parameters.

\end{enumerate}
\end{theorem*}

There is a variant of this procedure, wherein the augmented matrix is carried only to row-echelon form. The nonleading variables are assigned as parameters as before. Then the last equation (corresponding to the row-echelon form) is used to solve for the last leading variable in terms of the parameters. This last leading variable is then substituted into all the preceding equations. Then, the second last equation yields the second last leading variable, which is also substituted back. The process continues to give the general solution\index{general solution}\index{solution!general solution}. This procedure is called \index{back substitution}\textbf{back-substitution}. This procedure can be shown to be numerically more efficient and so is important when solving very large systems.\footnote{With $n$ equations where $n$ is large, gaussian elimination requires roughly $n^3/2$ multiplications and divisions, whereas this number is roughly $n^3/3$ if back substitution is used.}

\begin{example}{}{001095}
Find a condition on the numbers $a$, $b$, and $c$ such that the following system of equations is consistent. When that condition is satisfied, find all solutions (in terms of $a$, $b$, and $c$).\index{gaussian elimination!example}
\begin{equation*}
\arraycolsep=1pt
\begin{array}{rlrlrcr}
	 x_1 & + & 3x_2 & + & x_3 & = & a \\
	-x_1 & - & 2x_2 & + & x_3 & = & b \\
	3x_1 & + & 7x_2 & - & x_3 & = & c
\end{array}
\end{equation*}
\begin{solution}
We use gaussian elimination except that now the augmented matrix
\begin{equation*}
\leftB
\begin{array}{rrr|c}
1 & 3 & 1 & a\\
-1 & -2 & 1 & b \\
3 & 7 & -1 & c
\end{array}
\rightB
\end{equation*}
has entries $a$, $b$, and $c$ as well as known numbers. The first leading one is in place, so we create zeros below it in column 1:
\begin{equation*}
\leftB \begin{array}{rrr|c}
1 &  3 & 1 & a \\
0 &  1 & 2 & a + b \\
0 & -2& -4 & c -3a
\end{array} \rightB
\end{equation*}
The second leading $1$ has appeared, so use it to create zeros in the rest of column 2:
\begin{equation*}
\leftB \begin{array}{rrr|c}
	1 &  0 & -5 & -2a - 3b \\
	0 &  1 & 2 & a + b \\
	0 &  0 & 0 & c - a + 2b
\end{array} \rightB
\end{equation*}
Now the whole solution depends on the number $c - a + 2b = c - (a - 2b)$. The last row corresponds to an equation $0 = c - (a - 2b)$. If $c \neq a - 2b$, there is \textit{no} solution (just as in Example \ref{exa:001040}). Hence:

\begin{quotation}

The system is consistent if and only if $c = a - 2b$.

\end{quotation}

In this case the last matrix becomes
\begin{equation*}
\leftB \begin{array}{rrr|c}
1 &  0 & -5 & -2a - 3b \\
0 &  1 & 2 & a + b \\
0 &  0 & 0 & 0
\end{array} \rightB
\end{equation*}
Thus, if $c = a - 2b$, taking $x_3 = t$ where $t$ is a parameter gives the solutions
\begin{equation*}
x_1 = 5t - (2a + 3b) \quad x_2 = (a + b) - 2t \quad x_3 = t.
\end{equation*}
\end{solution}
\end{example}

\subsection*{Rank}

It can be proven that the \textit{reduced} row-echelon form of a matrix $A$ is uniquely determined by $A$. That is, no matter which series of row operations is used to carry $A$ to a reduced row-echelon matrix, the result will always be the same matrix. (A proof is given at the end of Section \ref{sec:2_5}.) By contrast, this is not true for row-echelon matrices: Different series of row operations can carry the same matrix $A$ to \textit{different} row-echelon matrices. Indeed, the matrix $A = 
\leftB \begin{array}{rrr}
	1 & -1 & 4 \\
	2 & -1 & 2
\end{array} \rightB$ can be carried (by one row operation) to the row-echelon matrix $
 \leftB \begin{array}{rrr}
	 1 & -1 & 4 \\
	 0 & 1 & -6
 \end{array} \rightB$, and then by another row operation to the (reduced) row-echelon matrix $
\leftB \begin{array}{rrr}
	1 & 0 & -2 \\
	0 & 1 & -6
\end{array} \rightB$. However, it \textit{is} true that the number $r$ of leading 1s must be the same in each of these row-echelon matrices (this will be proved in Chapter \ref{chap:5}). Hence, the number $r$ depends only on $A$ and not on the way in which $A$ is carried to row-echelon form.

\begin{definition}{Rank of a Matrix}{001120}
The \index{rank!matrix}\index{matrix!rank}\textbf{rank} of matrix $A$ is the number of leading $1$s in any row-echelon matrix to which $A$ can be carried by row operations.
\end{definition}

\begin{example}{}{001123}
Compute the rank of $A =  
\leftB \begin{array}{rrrr}
	1 & 1 & -1 & 4 \\
	2 & 1 &  3 & 0 \\
	0 & 1 & -5 & 8
\end{array} \rightB$.

\begin{solution}
The reduction of $A$ to row-echelon form is
\begin{equation*}
A =  
\leftB \begin{array}{rrrr}
1 & 1 & -1 & 4 \\
2 & 1 &  3 & 0 \\
0 & 1 & -5 & 8
\end{array} \rightB
\rightarrow
\leftB \begin{array}{rrrr}
1 & 1 & -1 & 4 \\
0 & -1 &  5 & -8 \\
0 &  1 & -5 & 8
\end{array} \rightB
\rightarrow
\leftB \begin{array}{rrrr}
1 & 1 & -1 & 4 \\
0 & 1 &  -5 & 8 \\
0 &  0 & 0 & 0
\end{array} \rightB
\end{equation*}
Because this row-echelon matrix has two leading $1$s, rank $A = 2$.
\end{solution}
\end{example}

Suppose that rank $A = r$, where $A$ is a matrix with $m$ rows and $n$ columns. Then $r \leq m$ because the leading $1$s lie in different rows, and $r \leq  n$ because the leading $1$s lie in different columns. Moreover, the rank has a useful application to equations. Recall that a system of linear equations is called consistent if it has at least one solution.

\begin{theorem}{}{001133}
Suppose a system of $m$ equations in $n$ variables is \textbf{consistent}, and that the rank of the augmented matrix is $r$.\index{solution!consistent system}\index{system of linear equations!consistent system}\index{system of linear equations!rank of a matrix}

\begin{enumerate}
\item The set of solutions involves exactly $n - r$ parameters.

\item If $r < n$, the system has infinitely many solutions.

\item If $r = n$, the system has a unique solution.

\end{enumerate}
\end{theorem}

\begin{proof}
The fact that the rank of the augmented matrix is $r$ means there are exactly $r$ leading variables, and hence exactly $n - r$ nonleading variables. These nonleading variables are all assigned as parameters in the gaussian algorithm, so the set of solutions involves exactly $n - r$ parameters. Hence if $r < n$, there is at least one parameter, and so infinitely many solutions. If $r = n$, there are no parameters and so a unique solution.
\end{proof}

Theorem \ref{thm:001133} shows that, for any system of linear equations, exactly three possibilities exist:

\begin{enumerate}\raggedright
\item \textit{No solution. This occurs when a row} $\leftB \begin{array}{ccccc} 0 & 0 & \cdots & 0 & 1 \end{array} \rightB$ \textit{occurs in the row-echelon form. This is the case where the system is inconsistent.}

\item \textit{Unique solution. This occurs when} every \textit{variable is a leading variable.}

\item \textit{Infinitely many solutions. This occurs when the system is consistent and there is at least one nonleading variable, so at least one parameter is involved.}\index{consistent system}

\end{enumerate}

\begin{example}{}{001154}
Suppose the matrix $A$ in Example \ref{exa:001123} is the augmented matrix of a system of $m = 3$ linear equations in $n = 3$ variables. As rank $A = r = 2$, the set of solutions will have $n - r = 1$ parameter. The reader can verify this fact directly.
\end{example}

Many important problems involve \textbf{linear inequalities} rather than \textbf{linear equations}\index{linear equation!vs. linear inequalities}\index{linear inequalities}. For example, a condition on the variables $x$ and $y$ might take the form of an inequality $2x - 5y \leq 4$ rather than an equality $2x - 5y = 4$. There is a technique (called the \index{simplex algorithm}\textbf{simplex algorithm}) for finding solutions to a system of such inequalities that maximizes a function of the form $p = ax + by$ where $a$ and $b$ are fixed constants. 

